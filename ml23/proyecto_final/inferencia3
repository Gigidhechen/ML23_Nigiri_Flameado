import cv2
import matplotlib.pyplot as plt
from network import Network
import os
import pathlib
import numpy as np
import torch
import torch.nn as nn
import torchvision
from dataset import get_loader
from utils import to_numpy, get_transforms, add_img_text


file_path = pathlib.Path(__file__).parent.absolute()
def predict(img_title_paths):
    modelo = Network(28, 10)
    modelo.load_model("modelo7.pth")
    for path in img_title_paths:
        im_file = (file_path / path).as_posix()
        assert os.path.isfile(im_file), f"El archivo {path} no existe"
        test_img=cv2.imread(im_file,cv2.IMREAD_GRAYSCALE)

        normalizedImg=np.zeros((800,800))
        normalizedImg=cv2.normalize(test_img,normalizedImg,0,255,cv2.NORM_MINMAX)  
        img = normalizedImg /255
        h, w = img.shape[:2]
        resize_value = 300
        img = cv2.resize(img, (w * resize_value // h, resize_value))
        img_resized = cv2.resize(test_img,(28,28),interpolation=cv2.INTER_LINEAR)
        img_resized=cv2.bitwise_not(img_resized) #se utiliza para que los pixeles sean negros o blancos.


        img_resized=img_resized.astype('float32')
        transformation=torchvision.transforms.ToTensor()
        img_resized=(transformation(img_resized))/255
        logits, proba = modelo.predict(img_resized)
        pred = torch.argmax(proba, -1).item()
        pred_label = str(pred)
        if len(img.shape) < 3:
            img=np.expand_dims(img,-1)
        img = add_img_text(img.astype('float32'), f"Pred: {pred_label}")

        cv2.imshow("prueba",img)
        cv2.waitKey(0)


if __name__=="__main__":
    # Direcciones relativas a este archivo
    img_paths = [
                 "./test_imgs/0.jpg",
                 "./test_imgs/1.jpg",
                 "./test_imgs/2.jpg",
                 "./test_imgs/3.jpg",
                 "./test_imgs/4.jpg",
                 "./test_imgs/5.jpg",
                 "./test_imgs/6.jpg",
                 "./test_imgs/7.jpg",
                 "./test_imgs/8.jpg",
                 "./test_imgs/9.jpg",
                 "./test_imgs/Azul_0.jpg",
                 "./test_imgs/Azul_1.jpg",
                 "./test_imgs/Azul_2.jpg",
                 "./test_imgs/Azul_3.jpg",
                 "./test_imgs/Azul_4.jpg",
                 "./test_imgs/Azul_5.jpg",
                 "./test_imgs/Azul_6.jpg",
                 "./test_imgs/Azul_7.jpg",
                 "./test_imgs/Azul_8.jpg",
                 "./test_imgs/Azul_9.jpg",
                 "./test_imgs/Blur_0.jpg",
                 "./test_imgs/Blur_1.jpg",
                 "./test_imgs/Blur_2.jpg",
                 "./test_imgs/Blur_3.jpg",
                 "./test_imgs/Blur_4.jpg",
                 "./test_imgs/Blur_5.jpg",
                 "./test_imgs/Blur_6.jpg",
                 "./test_imgs/Blur_7.jpg",
                 "./test_imgs/Blur_8.jpg",
                 "./test_imgs/Blur_9.jpg",
                 "./test_imgs/Noise_0.jpg",
                 "./test_imgs/Noise_1.jpg",
                 "./test_imgs/Noise_2.jpg",
                 "./test_imgs/Noise_3.jpg",
                 "./test_imgs/Noise_4.jpg",
                 "./test_imgs/Noise_5.jpg",
                 "./test_imgs/Noise_6.jpg",
                 "./test_imgs/Noise_7.jpg",
                 "./test_imgs/Noise_8.jpg",
                 "./test_imgs/Noise_9.jpg",
                 "./test_imgs/Pixel_0.jpg",
                 "./test_imgs/Pixel_1.jpg",
                 "./test_imgs/Pixel_2.jpg",
                 "./test_imgs/Pixel_3.jpg",
                 "./test_imgs/Pixel_4.jpg",
                 "./test_imgs/Pixel_5.jpg",
                 "./test_imgs/Pixel_6.jpg",
                 "./test_imgs/Pixel_7.jpg",
                 "./test_imgs/Pixel_8.jpg",
                 "./test_imgs/Pixel_9.jpg",
                 "./test_imgs/Rojo_0.jpg",
                 "./test_imgs/Rojo_1.jpg",
                 "./test_imgs/Rojo_2.jpg",
                 "./test_imgs/Rojo_3.jpg",
                 "./test_imgs/Rojo_4.jpg",
                 "./test_imgs/Rojo_5.jpg",
                 "./test_imgs/Rojo_6.jpg",
                 "./test_imgs/Rojo_7.jpg",
                 "./test_imgs/Rojo_8.jpg",
                 "./test_imgs/Rojo_9.jpg",
                 "./test_imgs/Rotate_0.jpg",
                 "./test_imgs/Rotate_1.jpg",
                 "./test_imgs/Rotate_2.jpg",
                 "./test_imgs/Rotate_3.jpg",
                 "./test_imgs/Rotate_4.jpg",
                 "./test_imgs/Rotate_5.jpg",
                 "./test_imgs/Rotate_6.jpg",
                 "./test_imgs/Rotate_7.jpg",
                 "./test_imgs/Rotate_8.jpg",
                 "./test_imgs/Rotate_9.jpg",
                 "./test_imgs/Verde_0.jpg",
                 "./test_imgs/Verde_1.jpg",
                 "./test_imgs/Verde_2.jpg",
                 "./test_imgs/Verde_3.jpg",
                 "./test_imgs/Verde_4.jpg",
                 "./test_imgs/Verde_5.jpg",
                 "./test_imgs/Verde_6.jpg",
                 "./test_imgs/Verde_7.jpg",
                 "./test_imgs/Verde_8.jpg",
                 "./test_imgs/Verde_9.jpg",
                 ]
    predict(img_paths)